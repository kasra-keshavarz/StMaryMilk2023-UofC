{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe3f683-4f41-4ce4-a3eb-9f2962c4440f",
   "metadata": {},
   "source": [
    "Note: make top line #!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370a9097-0137-4ef9-8a79-37ae07fffe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06654378-d1ce-498e-9266-d2f220cb953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here: /scratch/paulc600/final_hype_setup/full_calibration\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "cwd = os.getcwd()\n",
    "print(f'Here: {cwd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec8bd85-f21c-451b-aa34-deace0db9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_values(simulated, observed):\n",
    "    valid_indices = np.where((observed != -9999) & (simulated != -9999))\n",
    "    return simulated[valid_indices], observed[valid_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc825dd9-79bb-4bb7-94d3-998dac5c3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_rows(\n",
    "    array1: np.ndarray, \n",
    "    array2: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Removes rows from two arrays where either array has NaN values.\n",
    "    Retains the first row if it doesn't have any NaN values.\n",
    "    \n",
    "    Arguments:\n",
    "    array1: np.ndarray:\n",
    "        First input array\n",
    "    array2: np.ndarray\n",
    "        Second input array\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_array1: : np.ndarray\n",
    "        Cleaned array1 without NaN rows\n",
    "    cleaned_array2: np.ndarray\n",
    "        Cleaned array2 without NaN rows\n",
    "    \"\"\"\n",
    "    # checks for and removes any rows where either array has a value of NaN at a corresponding row \n",
    "    # including the first one\n",
    "    \n",
    "    mask = np.logical_and(~np.isnan(array1), ~np.isnan(array2))\n",
    "    if not np.isnan(array1[0]) and not np.isnan(array2[0]):\n",
    "        mask[0] = True\n",
    "    cleaned_array1 = array1[mask]\n",
    "    cleaned_array2 = array2[mask]\n",
    "    return cleaned_array1, cleaned_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74232359-b57b-41ff-a199-b8ed30fe03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kge(simulated_array, observed_array):\n",
    "    \"\"\"\n",
    "    Computes KGE (Kling-Gupta Efficiency) between observed and simulated values.\n",
    "\n",
    "    Parameters:\n",
    "        observed_array (numpy.ndarray): Array of observed values.\n",
    "        simulated_array (numpy.ndarray): Array of simulated values.\n",
    "\n",
    "    Returns:\n",
    "        float: KGE value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_coefficient = np.corrcoef(observed_array, simulated_array)[0, 1]\n",
    "    \n",
    "    # Calculate standard deviation ratio\n",
    "    std_observed = np.std(observed_array)\n",
    "    std_simulated = np.std(simulated_array)\n",
    "    std_ratio = std_simulated / std_observed\n",
    "    \n",
    "    # Calculate bias ratio\n",
    "    mean_observed = np.mean(observed_array)\n",
    "    mean_simulated = np.mean(simulated_array)\n",
    "    bias_ratio = mean_simulated / mean_observed\n",
    "    \n",
    "    # Calculate KGE\n",
    "    kge = 1 - np.sqrt((correlation_coefficient - 1)**2 + (std_ratio - 1)**2 + (bias_ratio - 1)**2)\n",
    "    return -kge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebcbd0f1-f30e-43e6-9c82-0b52fa441b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---------------------------------------------\n",
      "    HYPE version 5.25.1                  \n",
      " ---------------------------------------------\n",
      " New versions of HYPE at the HYPE Open Source \n",
      " Community website (hypecode.smhi.se), as well\n",
      " as information on up-coming courses.         \n",
      " ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Observation data checks will NOT be performed\n",
      " Setup- and model data checks will NOT be performed\n",
      "\n",
      "Program received signal SIGSEGV: Segmentation fault - invalid memory reference.\n",
      "\n",
      "Backtrace for this error:\n",
      "#0  0x2adc2cc6d730 in ???\n",
      "#1  0x2adc2cc6c8d5 in ???\n",
      "#2  0x2adc2d0e697f in ???\n",
      "#3  0x4b8a80 in ???\n",
      "#4  0x50c179 in ???\n",
      "#5  0x5cf2a4 in ???\n",
      "#6  0x401d4c in ???\n",
      "#7  0x2adc2d0d1e1a in ???\n",
      "#8  0x401d79 in ???\n",
      "#9  0xffffffffffffffff in ???\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./data/hype', './data/'], returncode=-11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hype\n",
    "hype_command  = './data/hype'\n",
    "subprocess.run([hype_command, './data/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557682c4-6132-41d6-b1b1-5e5a3e4b856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store total KGE values for each file\n",
    "total_kge_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fff358a-f529-4a8a-b0b2-ee9f1125ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb58cf0-efb5-40ab-a576-9998689cd64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory is:  /scratch/paulc600/final_hype_setup/02_cal/data\n"
     ]
    }
   ],
   "source": [
    "# Directory where Hype outputs are saved\n",
    "output_directory = os.path.join(os.getcwd(), 'data')\n",
    "print('Output directory is: ', output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37571b6-5cfc-47df-b50d-19b371bef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ranges = [('1981-01-01', '1984-12-31'),\n",
    "               ('1990-01-01', '1998-12-31'),\n",
    "               ('2004-01-01', '2007-12-31'),\n",
    "               ('2013-01-01', '2015-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b3ae68-3d6f-4380-90e6-d1c4fc8553b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through files in the output directory\n",
    "for filename in os.listdir(output_directory):\n",
    "    if filename.endswith(\".txt\") and filename.startswith(\"00\"):  # Process files with prefix '00' and end with '.txt'\n",
    "        filepath = os.path.join(output_directory, filename)\n",
    "\n",
    "        # Create empty lists to store observed and simulated data for each year range\n",
    "        simulated_data = []\n",
    "        observed_data = []\n",
    "\n",
    "        # Read tab-separated file into DataFrame\n",
    "        df = pd.read_csv(filepath, sep='\\t', index_col=0)\n",
    "        df = df.iloc[1:]  # Drop the first row\n",
    "\n",
    "        # Convert the index to datetime if it's not already in datetime format\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        # Process and filter DataFrame based on each year range\n",
    "        for start_date, end_date in year_ranges:\n",
    "            trimmed_df = df.loc[start_date:end_date]\n",
    "            simulated_data.append(trimmed_df['cout'].values.astype(float))  # Convert to float array\n",
    "            observed_data.append(trimmed_df['rout'].values.astype(float))  # Convert to float array\n",
    "\n",
    "        # Concatenate the lists of arrays into NumPy arrays\n",
    "        simulated_array = np.concatenate(simulated_data)\n",
    "        observed_array = np.concatenate(observed_data)\n",
    "        \n",
    "        # Remove invalid values (-9999) after concatenating arrays\n",
    "        simulated_array, observed_array = remove_invalid_values(simulated_array, observed_array)\n",
    "        \n",
    "        # check for and remove rows with nan\n",
    "        simulated_array, observed_array= remove_nan_rows(simulated_array, observed_array)\n",
    "        \n",
    "        # Check if both arrays have the same length\n",
    "        if len(observed_array) != len(simulated_array):\n",
    "            raise ValueError(f\"Observed and simulated data arrays for file {filename} have different lengths!\")\n",
    "\n",
    "        # Calculate KGE and bias for the current file\n",
    "        total_lognse = compute_kge(simulated_array, observed_array)\n",
    "\n",
    "        # Save total KGE to the list\n",
    "        total_kge_values.append(total_lognse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3592b782-2244-4294-97db-4e53b01f3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average KGE\n",
    "average_lognse = np.mean(total_kge_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f483490-a506-4ef5-8538-ef4bcb00367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the average KGE to a text file\n",
    "output_file_path = './average_kge.txt'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(str(average_lognse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19030d-b5af-4682-b12b-50eabf8b9dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easymore-env",
   "language": "python",
   "name": "easymore-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
